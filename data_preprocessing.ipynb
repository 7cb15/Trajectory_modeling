{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Clustering Approaches with AIS Shipping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import urllib\n",
    "import zipfile\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "from dipy.segment.metric import Metric\n",
    "from dipy.segment.metric import ResampleFeature\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import directed_hausdorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory to folder with trajectory files\n",
    "os.chdir(os.getcwd()+\"/tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set display options\n",
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Dataframe for EDA\n",
    "\n",
    "To get a sense of it, would be useful to figure out the overall timeframe (earliest/latest observation overall), lat/long coverage (whole world or other), overall distribution of time intervals, and average speed between consecutive measurements, like we were doing for other datasets (I can share the plots and/or the code if you wish).\n",
    "\n",
    "Figuring out the intervals during which each boat does not move (e.g. distance between each pair of measurements within a certain threshold or avg. speed between each pair of consecutive measurements within the interval not exceeding some threshold like 0.5mph; as some minimal movement can be detected just based on the measurement inaccuracies) would be useful. To implement that we can just traverse the trajectory and start accumulating “stationarity” interval each time we see a pair of consecutive measurements falls under speed threshold and keep accumulating them until the speed does not return to values above the threshold. If the stationarity period was long enough and satisfies some overall movement threshold we can then cut here and start a new “trip”. This way we split the trajectory into trips (segments of actual movement), but keep them grouped per vessel id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an empty dataframe with the columns from the NPZ files\n",
    "trajectories = pd.DataFrame(columns=['mmsi','timestamp','distance_from_shore','distance_from_port',\n",
    "                                     'speed','course','lat','lon'])\n",
    "\n",
    "counts_tracker = 0 #initialize counter for tracking\n",
    "\n",
    "#load npz files from directory\n",
    "for file in glob.glob('*.npz'):\n",
    "    try:\n",
    "        data = np.load(file) #load file\n",
    "        lst = data.files\n",
    "        for item in lst:\n",
    "            new_traj = pd.DataFrame(data[item])\n",
    "        trajectories = pd.concat([trajectories,new_traj])\n",
    "        counts_tracker += 1\n",
    "        print(counts_tracker) #track how many files have been loaded\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#df clean up\n",
    "trajectories.drop_duplicates(inplace=True) #drop duplicate entries\n",
    "trajectories.timestamp  = pd.to_datetime(trajectories.timestamp,unit='s') #convert to time stamp\n",
    "trajectories.reset_index(inplace=True) #reset\n",
    "trajectories['mmsi'] = trajectories['mmsi'].astype('int64') #set trajectory values to raw numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv for future use\n",
    "trajectories.to_csv('trajectories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some basic stats\n",
    "\n",
    "To get a sense of it, would be useful to figure out the overall timeframe (earliest/latest observation overall), lat/long coverage (whole world or other), overall distribution of time intervals, and average speed between consecutive measurements, like we were doing for other datasets (I can share the plots and/or the code if you wish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of unique boats\n",
    "len(trajectories['mmsi'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min and max of time range on data set\n",
    "print(\"Dates range from {} to {}\".format(min(trajectories.timestamp),max(trajectories.timestamp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat lon coverage\n",
    "print(\"Latitude ranges from {} to {}\".format(min(trajectories.lat),max(trajectories.lat)))\n",
    "print(\"Longitude ranges from {} to {}\".format(min(trajectories.lon),max(trajectories.lon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average number of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortest vs. longest trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall distribution of time intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average speed between consecutive measurements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Division of trajectories into trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take sample of trajectories for testing modeling\n",
    "trajectories_test = trajectories[trajectories['mmsi']==['','','']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data as arrays for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_list = list(trajectories.mmsi.unique()) #get a list of unique boat ids\n",
    "all_boat_locs = [] #initialize a list \n",
    "\n",
    "for i in boat_list:\n",
    "    boat_loc = []\n",
    "    boat = trajectories[trajectories.mmsi == i]\n",
    "    for index, row in boat.iterrows():\n",
    "        traj = [row['lat'],row['lon']]\n",
    "        traj = np.array(traj)\n",
    "        boat_loc.append(traj)\n",
    "    boat_loc = np.array(boat_loc)\n",
    "    all_boat_locs.append(boat_loc)\n",
    "    \n",
    "all_boat_locs = np.array(all_boat_locs) #convert to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_boat_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Bundles Approach Using DiPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class to calculate geographic distance\n",
    "class GPSdistance(Metric):\n",
    "    '''computes the average GPS distance between two trajectories'''\n",
    "    def __init__(self):\n",
    "        super(GPSdistance, self) \\\n",
    "        .__init__(feature=ResampleFeature(nb_points=\n",
    "    min(trajectories.groupby(['mmsi'])['speed'].count())))\n",
    "    \n",
    "    def are_compatible(self, shape1, shape2):\n",
    "        return len(shape1) == len(shape2)\n",
    "    \n",
    "    def dist(self, v1, v2):\n",
    "        x = [geopy.distance.vincenty(\n",
    "            [p[0][0],p[0][1], p[1][0],p[1][1]]).km for p in list(zip(v1,v2))]\n",
    "        currD = np.mean(x)\n",
    "        return currD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run quick bundles clustering\n",
    "metric = GPSdistance() #need to get this to work so that it's using geographic distance\n",
    "qb = QuickBundles(threshold=1)\n",
    "clusters = qb.cluster(all_boat_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nb. clusters:\", len(clusters))\n",
    "print(\"Cluster sizes:\", list(map(len, clusters)))\n",
    "print(\"Small clusters:\", clusters < 10)\n",
    "print(\"Streamlines indices of the first cluster:\\n\", clusters[0].indices)\n",
    "print(\"Centroid of the last cluster:\\n\", clusters[-1].centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
