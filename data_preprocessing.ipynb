{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Clustering Approaches with AIS Shipping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import urllib\n",
    "import zipfile\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "from dipy.segment.metric import Metric\n",
    "from dipy.segment.metric import ResampleFeature\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial.distance import directed_hausdorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory to folder with trajectory files\n",
    "os.chdir(os.getcwd()+\"/tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set display options\n",
    "pd.set_option('display.max_rows', 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Dataframe for EDA\n",
    "\n",
    "To get a sense of it, would be useful to figure out the overall timeframe (earliest/latest observation overall), lat/long coverage (whole world or other), overall distribution of time intervals, and average speed between consecutive measurements, like we were doing for other datasets (I can share the plots and/or the code if you wish).\n",
    "\n",
    "Figuring out the intervals during which each boat does not move (e.g. distance between each pair of measurements within a certain threshold or avg. speed between each pair of consecutive measurements within the interval not exceeding some threshold like 0.5mph; as some minimal movement can be detected just based on the measurement inaccuracies) would be useful. To implement that we can just traverse the trajectory and start accumulating “stationarity” interval each time we see a pair of consecutive measurements falls under speed threshold and keep accumulating them until the speed does not return to values above the threshold. If the stationarity period was long enough and satisfies some overall movement threshold we can then cut here and start a new “trip”. This way we split the trajectory into trips (segments of actual movement), but keep them grouped per vessel id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize an empty dataframe with the columns from the NPZ files\n",
    "trajectories = pd.DataFrame(columns=['mmsi','timestamp','distance_from_shore','distance_from_port',\n",
    "                                     'speed','course','lat','lon'])\n",
    "\n",
    "counts_tracker = 0 #initialize counter for tracking\n",
    "\n",
    "#load npz files from directory\n",
    "for file in glob.glob('*.npz'):\n",
    "    try:\n",
    "        data = np.load(file) #load file\n",
    "        lst = data.files\n",
    "        for item in lst:\n",
    "            new_traj = pd.DataFrame(data[item])\n",
    "        trajectories = pd.concat([trajectories,new_traj])\n",
    "        counts_tracker += 1\n",
    "        print(counts_tracker) #track how many files have been loaded\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#df clean up\n",
    "trajectories.drop_duplicates(inplace=True) #drop duplicate entries\n",
    "trajectories.timestamp  = pd.to_datetime(trajectories.timestamp,unit='s') #convert to time stamp\n",
    "trajectories.reset_index(inplace=True) #reset\n",
    "trajectories['mmsi'] = trajectories['mmsi'].astype('int64') #set trajectory values to raw numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv for future use\n",
    "trajectories.to_csv('trajectories.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
